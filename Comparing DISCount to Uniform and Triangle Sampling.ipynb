{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1. Import standard libraries and mount the drive to access shared drive**"
      ],
      "metadata": {
        "id": "4D3VTIxcaBGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "import csv"
      ],
      "metadata": {
        "id": "wM4DyKCf9SZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Import the image and respective JSON file, then set up tile size based on height and width**"
      ],
      "metadata": {
        "id": "63cF26_pelCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define basic information for easy modification\n",
        "img_path = '' # path to image\n",
        "json_path = '' # path to annotations\n",
        "type_of_annotation = '' # 'box' or 'point'\n",
        "q_probs_path = '' # path to npy output\n",
        "obj_name = 'people'"
      ],
      "metadata": {
        "id": "Kjl4s-pFaObX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read image and JSON\n",
        "img = mpimg.imread(img_path)\n",
        "obj = pd.read_json(json_path)\n",
        "q_probs = np.load(q_probs_path)[0][0]\n",
        "#obj = csv.reader(json_path)\n",
        "\n",
        "# See height and width\n",
        "img_height, img_width = len(img), len(img[0])\n",
        "print(f'Image size: {img_height} height x {img_width} width')"
      ],
      "metadata": {
        "id": "WQDKotPl901S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set tile size\n",
        "tile_size = 300 # modify if needed\n",
        "\n",
        "tiles_per_row = (img_width + tile_size - 1) // tile_size\n",
        "tiles_per_col = (img_height + tile_size - 1) // tile_size\n",
        "tiles_count = tiles_per_row * tiles_per_col # total number of tiles\n",
        "\n",
        "print(f'Tiles per row: {tiles_per_row}\\nTiles per column: {tiles_per_col}')\n",
        "print(f'Total number of tiles: {tiles_count}')"
      ],
      "metadata": {
        "id": "Gg34GWs3BOrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Get all objects' positions and show them on image**"
      ],
      "metadata": {
        "id": "YMbuvvwZEBED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all the objects list\n",
        "obj_coord = obj[obj.keys()[0]]['regions']\n",
        "obj_coord_list = [] # of type [x, y][], containing position of every object\n",
        "\n",
        "# Extract x- and y-coordinate based on annotation method\n",
        "if type_of_annotation == 'box':\n",
        "  for i in range(len(obj_coord)):\n",
        "    x_coord = (obj_coord[i]['shape_attributes']['x']+obj_coord[i]['shape_attributes']['width']/2)\n",
        "    y_coord = (obj_coord[i]['shape_attributes']['y']+obj_coord[i]['shape_attributes']['height']/2)\n",
        "    obj_coord_list.append([x_coord,y_coord])\n",
        "\n",
        "elif type_of_annotation == 'point':\n",
        "  for i in range(len(obj_coord)):\n",
        "    obj_coord_list.append([obj_coord[i]['shape_attributes']['cx'], obj_coord[i]['shape_attributes']['cy']])\n",
        "\n",
        "# Initiate true count\n",
        "true_count = len(obj_coord_list)"
      ],
      "metadata": {
        "id": "MBmbP4oA_THG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get separate x- and y-coordinate lists\n",
        "x_coords, y_coords = zip(*obj_coord_list)\n",
        "\n",
        "# Show image with annotations\n",
        "plt.imshow(img)\n",
        "plt.scatter(x_coords, y_coords, color='red', s=3, label=obj_name)  # Customize color and size\n",
        "plt.legend()\n",
        "# plt.axis('off')  # Turn off axis\n",
        "plt.show()\n",
        "\n",
        "print(f'Object count: {true_count}')"
      ],
      "metadata": {
        "id": "OyOW5nMEEcp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Tile the image, and output number of objects in each tile and distribution proposal**"
      ],
      "metadata": {
        "id": "2v1dEbtJkpwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tiles = [] # [tile_number, number_of_obj][]\n",
        "\n",
        "for i in range(tiles_per_row * tiles_per_col):\n",
        "    tiles.append([f'tiles{i}', 0]) # set up tiles with initial number of 0\n",
        "\n",
        "for obj in obj_coord_list:\n",
        "  x, y = obj\n",
        "  tiles[int(x // tile_size + (y // tile_size) * tiles_per_row)][1] += 1\n",
        "\n",
        "print(f'tiles = {tiles}')\n",
        "\n",
        "count_arr = []\n",
        "\n",
        "for tile in tiles:\n",
        "  count_arr.append(tile[1])\n",
        "\n",
        "# Plot the actual counts as a bar chart\n",
        "plt.title('Ground Truth Counts')\n",
        "plt.ylabel('Count')\n",
        "plt.xlabel('Position')\n",
        "plt.bar(np.arange(len(count_arr)), count_arr)\n",
        "plt.show()\n",
        "print(np.sum(count_arr))"
      ],
      "metadata": {
        "id": "e7Dp-MGxkj_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Import the normalized counts (from the computer vision model)**"
      ],
      "metadata": {
        "id": "MNkNjVUyX0D1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(threshold=50)\n",
        "\n",
        "sum = np.sum(q_probs) # total predicted count by the model\n",
        "\n",
        "q_probs_count = []\n",
        "\n",
        "q_probs_prob = []\n",
        "\n",
        "npy_tile_size = 0 # TODO: calculate new tile size based on the npy file (propotional to the original image's tile size)\n",
        "\n",
        "for y in range(0, np.shape(q_probs)[0], 87):\n",
        "  for x in range(0, np.shape(q_probs)[1], 87):\n",
        "    tile = np.sum(q_probs[y:y + 87, x:x + 87])\n",
        "    q_probs_count.append(tile)\n",
        "\n",
        "q_probs_count = np.array(q_probs_count)\n",
        "q_probs_prob = q_probs_count/np.sum(q_probs_count)\n",
        "\n",
        "print(q_probs_count) # list of count of each tile\n",
        "\n",
        "print(q_probs_prob) # list of probabilities of each tile\n",
        "\n",
        "print(np.sum(q_probs_prob)) # make sure that total probability is 1.0\n"
      ],
      "metadata": {
        "id": "PS-ZwCJvwACu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5a. Implement Importance Sampling**"
      ],
      "metadata": {
        "id": "YVH6-5cGYdsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick a random sample of size n according to q_probs\n",
        "sample_indices = np.random.choice(np.arange(len(q_probs_prob)), size=100, p=q_probs_prob)\n",
        "samples = q_probs_count[sample_indices]\n",
        "\n",
        "print(samples)"
      ],
      "metadata": {
        "id": "htOMtcVrYcfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5b. Implement Uniform Sampling**"
      ],
      "metadata": {
        "id": "sQiOZmq8F1DX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uniform_data = np.array([true_count/tiles_count]).repeat(tiles_count)\n",
        "\n",
        "uniform_probs = np.ones_like(uniform_data)/tiles_count"
      ],
      "metadata": {
        "id": "JgRKeIs4F0lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5c. Implement Triangle Sampling**"
      ],
      "metadata": {
        "id": "_3WNA_vvUl7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Triangle sampling distribution, increases linearly and then decreases linearly\n",
        "# x will be a numy array of integers between 0 and NUMCOUNT\n",
        "# If x is between  0 and NUMCOUNT//2 we want to return x+1 (increase linearly)\n",
        "# Otherwise, we want to return NUMCOUNT - x (decrease linearly)\n",
        "def q_triangle(count_arr):\n",
        "  arr = np.asarray(count_arr)\n",
        "\n",
        "  # N is the maximum value in arr (assumes arr == [0, 1 ,… , N])\n",
        "  N = len(arr) - 1\n",
        "  half = N // 2\n",
        "\n",
        "  # raw triangular weights: rising then falling\n",
        "  weights = np.where(\n",
        "        arr <= half,\n",
        "        arr + 1,      # from 0 up to half: weight = x+1\n",
        "        N - arr       # after half:        weight = N−x\n",
        "    )\n",
        "\n",
        "  # normalize to get probabilities\n",
        "  return weights / weights.sum()"
      ],
      "metadata": {
        "id": "YLMFD1uKWL1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the uniform, triangle and normal distribution all together\n",
        "plt.title('Proposal Distributions')\n",
        "plt.ylabel('Probability')\n",
        "plt.xlabel('Position')\n",
        "plt.plot(uniform_probs)\n",
        "plt.plot(q_triangle(np.arange(len(count_arr))))\n",
        "plt.plot(q_probs_prob)\n",
        "plt.legend(['Uniform', 'Triangle', 'DISCount'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TKUMXYUW8DCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Sample the distributions to compare with the ground truth**"
      ],
      "metadata": {
        "id": "RkUUcdjDVel1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Performs importance sampling and returns the mean and variance of each estimate\n",
        "# data is the array of counts whose mean we want to estimate\n",
        "# q_dist is the sampling distribution\n",
        "# n is the maximum number of samples to estimate the mean with\n",
        "NUM_COUNT = 247\n",
        "def run_importance_sampling(data, q_probs, n=NUM_COUNT):\n",
        "  n+=1\n",
        "\n",
        "  # Compute the probability of sampling each count in data based on q_dist\n",
        "  #q_probs = q_probs/np.sum(q_probs) # Ensure probabilities sum to 1\n",
        "\n",
        "  # Pick a random sample of size n according to q_probs\n",
        "  sample_indices = np.random.choice(np.arange(len(data)), size=n, p=q_probs)\n",
        "  samples = data[sample_indices]\n",
        "\n",
        "  # Calculate the weight p/q to adjust for some counts being more or less likely\n",
        "  weights = (1/(q_probs[sample_indices]*len(data)))\n",
        "\n",
        "  # Compute the mean and variance of the first k samples for all k from 1 to n\n",
        "  mean_estimates = np.cumsum(samples*weights)/np.arange(1, n+1)\n",
        "  var_estimates = (np.cumsum((samples*weights)**2)/np.arange(1, n+1) - mean_estimates**2)[1:]/np.arange(1, n)\n",
        "\n",
        "  # Multiply by the number of counts to get an estimate for the total count\n",
        "  return mean_estimates[1:]*len(data), var_estimates*(len(data)**2)\n",
        "\n",
        "# Estimate the total count with uniform sampling and normal sampling\n",
        "mean_estimates_uniform, var_estimates_uniform = run_importance_sampling(np.array(count_arr), uniform_probs)\n",
        "mean_estimates_normal, var_estimates_normal = run_importance_sampling(np.array(count_arr), q_probs_prob)\n",
        "mean_estimates_triangle, var_estimates_triangle = run_importance_sampling(np.array(count_arr), q_triangle(q_probs_count))"
      ],
      "metadata": {
        "id": "pv5OP8TimGAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############# JUST COMMENT OUT THE BELOW TO MAKE IT ONE RUN #############################\n",
        "\n",
        "# Will add the simulations and take the means of 100 simulations for normal estimate\n",
        "runs = 5\n",
        "\n",
        "mean_sum_normal_crowd = np.zeros(NUM_COUNT, dtype=float)\n",
        "var_sum_normal_crowd  = np.zeros(NUM_COUNT, dtype=float)\n",
        "\n",
        "for _ in range(runs):\n",
        "    mean_estimates_normal, var_estimates_normal = run_importance_sampling(np.array(count_arr),q_probs_prob)\n",
        "    mean_sum_normal_crowd += mean_estimates_normal\n",
        "    var_sum_normal_crowd  += var_estimates_normal\n",
        "\n",
        "mean_estimates_normal_crowd = mean_sum_normal_crowd / runs\n",
        "var_estimates_normal_crowd  = var_sum_normal_crowd  / runs\n",
        "\n",
        "# Will add the simulations and take the means of 100 simulations for uniform estimate\n",
        "\n",
        "mean_sum_uniform_crowd = np.zeros(NUM_COUNT, dtype=float)\n",
        "var_sum_uniform_crowd  = np.zeros(NUM_COUNT, dtype=float)\n",
        "\n",
        "for _ in range(runs):\n",
        "    mean_estimates_uniform, var_estimates_uniform = run_importance_sampling(np.array(count_arr), uniform_probs)\n",
        "    mean_sum_uniform_crowd += mean_estimates_uniform\n",
        "    var_sum_uniform_crowd  += var_estimates_uniform\n",
        "\n",
        "mean_estimates_uniform_crowd = mean_sum_uniform_crowd / runs\n",
        "var_estimates_uniform_crowd  = var_sum_uniform_crowd  / runs\n",
        "\n",
        "\n",
        "mean_sum_triangle_crowd = np.zeros(NUM_COUNT, dtype=float)\n",
        "var_sum_triangle_crowd  = np.zeros(NUM_COUNT, dtype=float)\n",
        "\n",
        "for _ in range(runs):\n",
        "    mean_estimates_triangle, var_estimates_triangle = run_importance_sampling(np.array(count_arr), uniform_probs)\n",
        "    mean_sum_triangle_crowd += mean_estimates_triangle\n",
        "    var_sum_triangle_crowd  += var_estimates_triangle\n",
        "\n",
        "mean_estimates_triangle_crowd = mean_sum_triangle_crowd / runs\n",
        "var_estimates_triangle_crowd  = var_sum_triangle_crowd  / runs\n",
        "\n",
        "\n",
        "############# JUST COMMENT OUT THE ABOVE TO MAKE IT ONE RUN #############################\n",
        "\n",
        "\n",
        "# Plot the estimates as a function of samples\n",
        "xs = np.arange(1,len(mean_estimates_uniform_crowd)+1)\n",
        "plt.plot(xs, mean_estimates_uniform_crowd, label='Uniform')\n",
        "plt.fill_between(xs, mean_estimates_triangle_crowd-1.645*(var_estimates_triangle_crowd**0.5), mean_estimates_triangle_crowd+1.645*(var_estimates_triangle_crowd**0.5), alpha=0.2)\n",
        "plt.plot(xs, mean_estimates_normal_crowd, label='DISCount')\n",
        "plt.fill_between(xs, mean_estimates_uniform_crowd-1.645*(var_estimates_uniform_crowd**0.5), mean_estimates_uniform_crowd+1.645*(var_estimates_uniform_crowd**0.5), alpha=0.2)\n",
        "plt.plot(xs, mean_estimates_triangle_crowd, label='Triangle')\n",
        "plt.fill_between(xs, mean_estimates_normal_crowd-1.645*(var_estimates_normal_crowd**0.5), mean_estimates_normal_crowd+1.645*(var_estimates_normal_crowd**0.5), alpha=0.2)\n",
        "plt.hlines(true_count, 0, len(mean_estimates_normal_crowd), linestyles='--', label='Ground Truth', color='black')\n",
        "plt.ylabel('Total Count')\n",
        "plt.xlabel('Number of Samples')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DQILv8v6HzBB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}